# BIG-DATA-ANALYSIS

"COMPANY": CODTECH IT SOLUTIONS

"NAME": Ramisetty Meghana

"INTERN ID": CTIS0393

"DOMAIN": DATA ANALYTICS

"DURATION": 8 WEEKS

"MENTOR": NEELA SANTHOSH

"DESCRIPTION OF TASK1": This task was performed using Microsoft Excel with the support of online learning resources such as Google. Although tools like PySpark and Dask are mainly used for very large-scale distributed systems, Excel can also be effectively used to analyze large datasets for academic and internship-level projects. Excel provides powerful features for data cleaning, transformation, analysis, and visualization, making it suitable for understanding big data concepts and deriving meaningful insights.

First, the large dataset was collected from online sources using Google. Publicly available datasets such as sales records, customer transactions, or business performance data were searched and downloaded in CSV format. Google helped in identifying reliable datasets and also provided guidance on how to handle large files in Excel, such as using proper formatting, filtering, and efficient data handling techniques. After downloading the dataset, it was imported into Excel using the “From Text/CSV” option under the Data tab. This ensured that the dataset was loaded correctly with appropriate column names and data types.

Once the data was loaded, the first step was data cleaning. This included removing duplicate records, handling missing values, and correcting inconsistent data formats. Excel functions like Remove Duplicates, Filter, IF, ISBLANK, and Conditional Formatting were used to identify and fix errors in the dataset. Unnecessary columns that were not required for analysis were removed to reduce complexity and improve performance. This step is crucial in big data analysis because clean data leads to more accurate and reliable results.

After cleaning, data transformation was performed. New columns were created using Excel formulas to calculate values such as total sales, profit, or averages. For example, if the dataset contained price and quantity columns, a new column was added to calculate total sales using a simple multiplication formula. Google was helpful in understanding advanced Excel formulas and functions such as SUMIF, COUNTIF, VLOOKUP/XLOOKUP, and Pivot Tables.

The main analysis was carried out using Pivot Tables, which are one of the most powerful tools in Excel for big data processing. Pivot Tables were used to summarize large amounts of data quickly and efficiently. For instance, total sales were calculated category-wise, region-wise, or month-wise. Average values, counts, and maximum or minimum values were also obtained. This helped in identifying patterns, trends, and performance indicators within the dataset.

To demonstrate scalability, Excel handled thousands of rows of data and performed computations in a short time. Although Excel is not designed for massive distributed datasets like PySpark, it still showed its capability to process large volumes of structured data effectively on a single system. By using filters, sorting, and Pivot Tables, large datasets were managed smoothly and insights were generated efficiently.

Visualization was another important part of the analysis. Charts such as bar graphs, pie charts, and line charts were created to represent the insights visually. For example, a bar chart was used to show the top-performing categories based on total sales, and a line chart was used to show sales trends over time. These visualizations made the results easy to understand and interpret.

In conclusion, this big data analysis task was successfully performed using Microsoft Excel with the help of Google for guidance and learning. Excel was used for data collection, cleaning, transformation, analysis, and visualization. The project demonstrated how large datasets can be processed and analyzed efficiently even without advanced big data tools. It provided valuable experience in handling real-world data, deriving insights, and understanding the fundamentals of big data analysis. This approach fulfills the internship requirement by showing practical data processing skills and analytical thinking.

"OUT PUT OF PIC":

<img width="765" height="415" alt="Image" src="https://github.com/user-attachments/assets/33887c1d-8242-4195-8108-f7ad7c38d681" />
